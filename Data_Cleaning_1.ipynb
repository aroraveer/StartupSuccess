{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExoeJY4EoV4Y"
      },
      "outputs": [],
      "source": [
        "#Code Below is by Veer Arora\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUqKngmRoV4c"
      },
      "outputs": [],
      "source": [
        "data1=pd.read_csv('modified_Page_1_39.csv')\n",
        "data2=pd.read_csv('modified_Page_41_73.csv')\n",
        "data3=pd.read_csv('modified_Page_75_140.csv')\n",
        "data4=pd.read_csv('modified_Page_140_252.csv')\n",
        "data5=pd.read_csv('modified_Page_253_X.csv')\n",
        "\n",
        "data=[data1,data2,data3,data4,data5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIruLy65oV4d"
      },
      "outputs": [],
      "source": [
        "data=[data1,data2,data3,data4,data5]\n",
        "# drop columns containing the name 'Drop'\n",
        "for df in data:\n",
        "    drop_columns = [col for col in df.columns if 'Drop' in col]\n",
        "    df.drop(columns=drop_columns, inplace=True)\n",
        "\n",
        "data1, data2, data3, data4, data5 = data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz6nwpaKoV4d"
      },
      "source": [
        "## Fixing Data from Page 1-39"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UTx5YWjoV4f"
      },
      "source": [
        "Combining Positive and Negative EBITDA values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o1xQAx9oV4f"
      },
      "outputs": [],
      "source": [
        "# function to convert values like (0.06) to negative numeric -0.06\n",
        "def clean_negative_values(column):\n",
        "    return column.replace(r'\\((.*?)\\)', r'-\\1', regex=True).replace('None', None).astype(float)\n",
        "\n",
        "# convertion\n",
        "columns_to_clean = ['EBITDA Negative']\n",
        "for column in columns_to_clean:\n",
        "    data1[column] = clean_negative_values(data1[column])\n",
        "\n",
        "# Create Ebitda from positive and negative\n",
        "data1['EBITDA'] = data1['EBITDA Negative'].fillna(data1['EBITDA Positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDJ8pGvcoV4f"
      },
      "source": [
        "Droping the columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXxMcm2QoV4g"
      },
      "outputs": [],
      "source": [
        "# drop cleanup columns\n",
        "drop_columns1= ['EBITDA Negative','EBITDA Positive']\n",
        "data1.drop(columns=drop_columns1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmYxvDUVoV4g"
      },
      "source": [
        "## Fixing Data from Page 41-73"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_xXsfKooV4g"
      },
      "source": [
        "Fixing the Post Valuation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOeSIkL1oV4h"
      },
      "outputs": [],
      "source": [
        "# updating post valuation based on found pattern leading to data issues\n",
        "data2['Post Valuation new'] = data2['Post Valuation 3'].combine_first(\n",
        "    data2['Post Valuation 2 (use to Replace in other column) / Becomes Net Income if Replaced by Postvaluation 3']\n",
        ").combine_first(\n",
        "    data2['Post Valuation']\n",
        ")\n",
        "\n",
        "data2['Post Valuation']= data2['Post Valuation new']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOj0v-pNoV4h"
      },
      "source": [
        "Fixing Net Income Positive Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmT8_DSpoV4h"
      },
      "outputs": [],
      "source": [
        "# updating Net Income based on found pattern leading to data issues\n",
        "data2['Net Income Positive'] = data2.apply(\n",
        "    lambda row: row['Post Valuation 2 (use to Replace in other column) / Becomes Net Income if Replaced by Postvaluation 3']\n",
        "    if pd.notna(row['Post Valuation 3']) else None,\n",
        "    axis=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlsEYg1NoV4i"
      },
      "source": [
        "Fixing negative and positive EBITDA and Net Income Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PCEE5FpoV4i"
      },
      "outputs": [],
      "source": [
        "# convert to true negative numbers\n",
        "columns_to_clean = ['EBITDA Negative', 'Net Income Negative']\n",
        "for column in columns_to_clean:\n",
        "    data2[column] = clean_negative_values(data2[column])\n",
        "\n",
        "# update EBITDA and Net Income columns\n",
        "data2['EBITDA'] = data2['EBITDA Negative'].fillna(data2['EBITDA Positive'])\n",
        "data2['Net Income'] = data2['Net Income Negative'].fillna(data2['Net Income Positive'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8pmQE5soV4j"
      },
      "source": [
        "Droping and cleaning the Column Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM0LHlcUoV4j"
      },
      "outputs": [],
      "source": [
        "#Making the column names uniform\n",
        "data2['CEO Education']= data2['CEO Education / Sometimes DealType 2']\n",
        "data2['Deal Type 2']= data2['Deal Type 2 / Sometime Education']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCNWbLWtoV4j"
      },
      "outputs": [],
      "source": [
        "# drop cleanup columns\n",
        "drop_columns2= ['Post Valuation 2 (use to Replace in other column) / Becomes Net Income if Replaced by Postvaluation 3', 'EBITDA Negative', 'Net Income Negative', 'EBITDA Positive', 'Post Valuation 3',\n",
        "'Net Income Positive','Post Valuation new', 'CEO Education / Sometimes DealType 2','Deal Type 2 / Sometime Education']\n",
        "data2.drop(columns=drop_columns2, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MYcGV5uoV4j"
      },
      "source": [
        "## Fixing Data from Page 75-140"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxfVfdpSoV4k"
      },
      "source": [
        "Convert EBITDA and Net Income which are all negative to true negaitves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUaLl55voV4k"
      },
      "outputs": [],
      "source": [
        "# convert to true negative numbers\n",
        "columns_to_clean = ['EBITDA', 'Net Income']\n",
        "for column in columns_to_clean:\n",
        "    data3[column] = clean_negative_values(data3[column])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz9IJlKeoV4k"
      },
      "source": [
        "Fixing Columns with data in mulltiple other columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJunP6vMoV4k"
      },
      "outputs": [],
      "source": [
        "# Update Investors data by combining columns where the data may lie\n",
        "data3['New Investors'] = data3['New Investors/ Investors'].fillna('') + ', ' + data3['Vertical (Sometimes), Investors Sometimes'].fillna('')\n",
        "data3['New Investors'] = data3['New Investors'].str.strip(', ').replace('^,|,$', '', regex=True)\n",
        "\n",
        "# Update Vertical data by combining columns where the data may lie\n",
        "data3['Vertical'] = data3['Vertical / Sometimes Series'].fillna('') + ', ' + data3['Vertical (Sometimes), Investors Sometimes'].fillna('')\n",
        "data3['Vertical'] = data3['Vertical'].str.strip(', ').replace('^,|,$', '', regex=True)\n",
        "\n",
        "# Update Deal Type 2 data by combining columns where the data may lie\n",
        "data3['Deal Type 2'] = data3['Deal Type 2'].fillna('') + ', ' + data3['Vertical / Sometimes Series'].fillna('')\n",
        "data3['Deal Type 2'] = data3['Deal Type 2'].str.strip(', ').replace('^,|,$', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QasbQUz1oV4l"
      },
      "source": [
        "Renam / Drop Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtWVHUGzoV4l"
      },
      "outputs": [],
      "source": [
        "data3.drop(columns=['New Investors/ Investors', 'Vertical (Sometimes), Investors Sometimes',\n",
        "                    'Vertical / Sometimes Series','Current Financing Status'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNJhVcESoV4l"
      },
      "source": [
        "## Fixing Data from Page 140-252"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lnTKUssoV4m"
      },
      "source": [
        "Fixing the Post Valuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pHqbKBBoV4m"
      },
      "outputs": [],
      "source": [
        "# Update Post Valuation column based on found pattern\n",
        "data4['Post Valuation'] = data4['Replace Post Valuation with this cell value'].combine_first(\n",
        "    data4['Post Valuation']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0XGMLICoV4m"
      },
      "source": [
        "Convert EBITDA, Net Income, Gross Profit which are all negative to true negaitves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvP0uGQFoV4m"
      },
      "outputs": [],
      "source": [
        "# convert to true negative numbers\n",
        "columns_to_clean = ['EBITDA negative', 'Net Income negative', 'Gross Profit negative']\n",
        "for column in columns_to_clean:\n",
        "    data4[column] = clean_negative_values(data4[column])\n",
        "\n",
        "# Update EBITDA, Net Income and Gross PRofit with true negative numbers\n",
        "data4['EBITDA'] = data4['EBITDA negative']\n",
        "data4['Net Income'] = data4['Net Income negative']\n",
        "data4['Gross Profit'] = data4['Gross Profit negative']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5FYLcKdoV4n"
      },
      "outputs": [],
      "source": [
        "data4.drop(columns=['EBITDA negative', 'Gross Profit negative',\n",
        "       'Net Income negative', 'Replace Post Valuation with this cell value', 'Series'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFZ34U6koV4n"
      },
      "source": [
        "## Fixing Data from Page 253 - X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGdFlLXQoV4o"
      },
      "source": [
        "Convert EBITDA, Net Income which are all negative to true negaitves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT7h_R5AoV4o"
      },
      "outputs": [],
      "source": [
        "# convert to true negative numbers\n",
        "columns_to_clean = ['EBITDA negative', 'Net Income negative']\n",
        "for column in columns_to_clean:\n",
        "    data5[column] = clean_negative_values(data5[column])\n",
        "\n",
        "# Update EBITDA and Net Income columns\n",
        "data5['EBITDA'] = data5['EBITDA negative']\n",
        "data5['Net Income'] = data5['Net Income negative']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcvmhO-5oV4p"
      },
      "source": [
        "Creating Columns with data from multiple other columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfQ3-5dmoV4p"
      },
      "outputs": [],
      "source": [
        "# Deal Date\n",
        "data5['Deal Date'] = data5['Vertical or Deal Date']\n",
        "\n",
        "# combine the data from multiple columns for Investors data\n",
        "data5['New Investors'] = data5['Vertical, Investor, Deal Type 2'].fillna('') + ', ' + data5['Can be Investor, Deal Type 2, Vertical'].fillna('')\n",
        "data5['New Investors'] = data5['New Investors'].str.strip(', ').replace('^,|,$', '', regex=True)\n",
        "\n",
        "# combine the data from multiple columns for Vertical data\n",
        "data5['Vertical'] = data5['Vertical, Investor, Deal Type 2'].fillna('') + ', ' + data5['Can be Investor, Deal Type 2, Vertical'].fillna('')+ ', ' + data5['Vertical or Deal Date'].fillna('')\n",
        "data5['Vertical'] = data5['Vertical'].str.strip(', ').replace('^,|,$', '', regex=True)\n",
        "\n",
        "#combine the data from multiple columns for Deal Type 2 data\n",
        "data5['Deal Type 2'] = data5['Vertical, Investor, Deal Type 2'].fillna('') + ', ' + data5['Can be Investor, Deal Type 2, Vertical'].fillna('')\n",
        "data5['Deal Type 2'] = data5['Deal Type 2'].str.strip(', ').replace('^,|,$', '', regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m34tE4qoV4q"
      },
      "source": [
        "Dropping unncessary Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhgHZwoJoV4q"
      },
      "outputs": [],
      "source": [
        "data5.drop(columns=['EBITDA negative', 'Net Income negative',\n",
        "'Vertical or Deal Date',\n",
        "'Can be Investor, Deal Type 2, Vertical',\n",
        "'Vertical, Investor, Deal Type 2'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RDSIjQmoV4q"
      },
      "source": [
        "## Saving the Data in new CSV files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_PdllLnoV4r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# save data to CSV\n",
        "folder_path = \"/Users/veerarora/Desktop/INDENG 242A/Team Project/Pitchbook\"\n",
        "file1  = os.path.join(folder_path, f\"Cleanup_Page_1_39.csv\")\n",
        "data1.to_csv(file1, index=False)\n",
        "file2  = os.path.join(folder_path, f\"Cleanup_Page_41_73.csv\")\n",
        "data2.to_csv(file2, index=False)\n",
        "file3  = os.path.join(folder_path, f\"Cleanup_Page_75_140.csv\")\n",
        "data3.to_csv(file3, index=False)\n",
        "file4  = os.path.join(folder_path, f\"Cleanup_Page_140_252.csv\")\n",
        "data4.to_csv(file4, index=False)\n",
        "file5  = os.path.join(folder_path, f\"Cleanup_Page_253_X.csv\")\n",
        "data5.to_csv(file5, index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}